{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD = \"DQN\" # or \"PPO\"\n",
    "\n",
    "TRAIN_LENGHT = 2_000_000\n",
    "EVALUATION_GAMES = 2_000\n",
    "NUM_ENVS = 1\n",
    "POLICY = \"CNN\" # or \"MLP\"\n",
    "\n",
    "\n",
    "# If true shows an agent 4 frames instead of 1\n",
    "# Allows an agent to determin velocity and movement direction when learning from pixels\n",
    "# Not a default hyper-param but should probably be used\n",
    "FRAME_STACK = True \n",
    "\n",
    "# If true a episode is reset apon losing a life instead of losing all lifes\n",
    "# Used in the deepmind papers\n",
    "END_OF_LIFE_IS_END_OF_GAME = False\n",
    "\n",
    "ENV_SEED = 1\n",
    "\n",
    "# Disables the effect of the next hyper parameters\n",
    "DEFAULT_HYPER_PARAMS = True\n",
    "\n",
    "LEARNING_RATE = 0.00001\n",
    "\n",
    "DQN_BUFFER_SIZE = 200_000\n",
    "# Number of frames to simulate between training the network\n",
    "DQN_TRAIN_FREQ = 2\n",
    "# Number of initial random frames\n",
    "DQN_LEARNING_STARTS = 10_000\n",
    "# Number of frames between updating the target network \n",
    "DQN_TARGET_NETWORK_UPDATE_FREQ = 10_000\n",
    "\n",
    "MODEL_NAME = \"model_{}_{}_{}\".format(METHOD,POLICY,TRAIN_LENGHT)\n",
    "\n",
    "# Load a model from a file of name MODEL_NAME\n",
    "LOAD_MODEL = False\n",
    "LOAD_NAME = MODEL_NAME + \"_checkpoint\"\n",
    "\n",
    "EVAL_FREQUENCY = 10_000\n",
    "EVAL_EPISODES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the environment if on colab\n",
    "try:\n",
    "    import google.colab\n",
    "    import os\n",
    "    %tensorflow_version 1.15\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install stable-baselines gym[atari] tqdm\n",
    "    colab.drive.mount('/content/drive')\n",
    "    os.chdir('/content/drive/My Drive/CHANGE_THIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.deepq.policies import MlpPolicy as DQNMlpPolicy, CnnPolicy as DQNCnnPolicy\n",
    "from stable_baselines.common.policies import MlpPolicy, CnnPolicy \n",
    "from stable_baselines.common.cmd_util import make_atari_env\n",
    "from stable_baselines.common import callbacks\n",
    "from stable_baselines import DQN, PPO2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "if METHOD == \"DQN\":\n",
    "    NUM_ENVS = 1\n",
    "\n",
    "wrapper_kwargs = {\n",
    "    'frame_stack': FRAME_STACK,\n",
    "    'episode_life': END_OF_LIFE_IS_END_OF_GAME\n",
    "}\n",
    "env = make_atari_env(\"MsPacmanNoFrameskip-v0\",NUM_ENVS,ENV_SEED,wrapper_kwargs=wrapper_kwargs)\n",
    "\n",
    "\n",
    "class EvalScoreLogger(callbacks.EvalCallback):\n",
    "    def __init__(self,path,*args, **kwargs):\n",
    "        super(EvalScoreLogger, self).__init__(*args,**kwargs)\n",
    "        self.file_path = path\n",
    "    \n",
    "    def _on_training_start(self):\n",
    "        self.log_file = open(self.file_path,\"w\")\n",
    "        \n",
    "    def _on_step(self):\n",
    "        super(EvalScoreLogger,self)._on_step()\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "            time_steps = self.n_calls\n",
    "            self.log_file.write(\"{},{}\\n\".format(time_steps,self.last_mean_reward))\n",
    "            self.log_file.flush()\n",
    "        \n",
    "    def _on_training_end(self):\n",
    "        self.log_file.close()\n",
    "        \n",
    "\n",
    "class PBarCallback(callbacks.BaseCallback):\n",
    "    def __init__(self,verbose=0):\n",
    "        super(PBarCallback, self).__init__(verbose)\n",
    "        self.pbar = None\n",
    "        \n",
    "    def _on_training_start(self):\n",
    "        self.pbar = tqdm(total=self.locals['total_timesteps'])\n",
    "        \n",
    "    def _on_step(self):\n",
    "        self.pbar.n = self.n_calls\n",
    "        self.pbar.update(0)\n",
    "        return True\n",
    "        \n",
    "    def _on_training_end(self):\n",
    "        self.pbar.n = self.n_calls\n",
    "        self.pbar.update(0)\n",
    "        self.pbar.close()\n",
    "        \n",
    "#eval_log = open(\"eval_log.csv\",\"w\")\n",
    "\n",
    "cb = callbacks.CallbackList([\n",
    "    PBarCallback(TRAIN_LENGHT),\n",
    "    callbacks.CheckpointCallback(save_freq=10_000,save_path=\"./checkpoints/\",name_prefix=MODEL_NAME),\n",
    "    EvalScoreLogger('eval_score.csv',env,\n",
    "                           eval_freq=EVAL_FREQUENCY,\n",
    "                           n_eval_episodes = EVAL_EPISODES,\n",
    "                           best_model_save_path=\"./best/\",\n",
    "                           verbose=1)\n",
    "])\n",
    "\n",
    "if METHOD == \"DQN\":\n",
    "    policy = DQNMlpPolicy if POLICY == \"MLP\" else DQNCnnPolicy\n",
    "    params = {} if DEFAULT_HYPER_PARAMS else {\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'buffer_size': DQN_BUFFER_SIZE,\n",
    "        'train_freq': DQN_TRAIN_FREQ,\n",
    "        'learning_starts': DQN_LEARNING_STARTS,\n",
    "        'target_network_update_freq': DQN_TARGET_NETWORK_UPDATE_FREQ,\n",
    "    }\n",
    "    model = DQN(policy,env,**params)\n",
    "else:\n",
    "    policy = MlpPolicy if POLICY == \"MLP\" else CnnPolicy\n",
    "    params = {} if DEFAULT_HYPER_PARAMS else {\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "    }\n",
    "    model = PPO2(policy,env,**params)\n",
    "    \n",
    "if LOAD_MODEL:\n",
    "    model.load(LOAD_NAME,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(TRAIN_LENGHT,callback=cb)\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
